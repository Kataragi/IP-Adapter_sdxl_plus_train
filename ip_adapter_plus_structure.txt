=== Nested Structure of /home/akishiro/IP-Adapter/models/pretrained_ip_adapter/ip-adapter-plus_sdxl_vit-h.safetensors ===

- image_proj.latents (type: <class 'torch.Tensor'>, shape: torch.Size([1, 16, 1280]))
- image_proj.layers.0.0.norm1.bias (type: <class 'torch.Tensor'>, shape: torch.Size([1280]))
- image_proj.layers.0.0.norm1.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280]))
- image_proj.layers.0.0.norm2.bias (type: <class 'torch.Tensor'>, shape: torch.Size([1280]))
- image_proj.layers.0.0.norm2.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280]))
- image_proj.layers.0.0.to_kv.weight (type: <class 'torch.Tensor'>, shape: torch.Size([2560, 1280]))
- image_proj.layers.0.0.to_out.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 1280]))
- image_proj.layers.0.0.to_q.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 1280]))
- image_proj.layers.0.1.0.bias (type: <class 'torch.Tensor'>, shape: torch.Size([1280]))
- image_proj.layers.0.1.0.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280]))
- image_proj.layers.0.1.1.weight (type: <class 'torch.Tensor'>, shape: torch.Size([5120, 1280]))
- image_proj.layers.0.1.3.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 5120]))
- image_proj.layers.1.0.norm1.bias (type: <class 'torch.Tensor'>, shape: torch.Size([1280]))
- image_proj.layers.1.0.norm1.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280]))
- image_proj.layers.1.0.norm2.bias (type: <class 'torch.Tensor'>, shape: torch.Size([1280]))
- image_proj.layers.1.0.norm2.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280]))
- image_proj.layers.1.0.to_kv.weight (type: <class 'torch.Tensor'>, shape: torch.Size([2560, 1280]))
- image_proj.layers.1.0.to_out.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 1280]))
- image_proj.layers.1.0.to_q.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 1280]))
- image_proj.layers.1.1.0.bias (type: <class 'torch.Tensor'>, shape: torch.Size([1280]))
- image_proj.layers.1.1.0.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280]))
- image_proj.layers.1.1.1.weight (type: <class 'torch.Tensor'>, shape: torch.Size([5120, 1280]))
- image_proj.layers.1.1.3.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 5120]))
- image_proj.layers.2.0.norm1.bias (type: <class 'torch.Tensor'>, shape: torch.Size([1280]))
- image_proj.layers.2.0.norm1.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280]))
- image_proj.layers.2.0.norm2.bias (type: <class 'torch.Tensor'>, shape: torch.Size([1280]))
- image_proj.layers.2.0.norm2.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280]))
- image_proj.layers.2.0.to_kv.weight (type: <class 'torch.Tensor'>, shape: torch.Size([2560, 1280]))
- image_proj.layers.2.0.to_out.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 1280]))
- image_proj.layers.2.0.to_q.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 1280]))
- image_proj.layers.2.1.0.bias (type: <class 'torch.Tensor'>, shape: torch.Size([1280]))
- image_proj.layers.2.1.0.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280]))
- image_proj.layers.2.1.1.weight (type: <class 'torch.Tensor'>, shape: torch.Size([5120, 1280]))
- image_proj.layers.2.1.3.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 5120]))
- image_proj.layers.3.0.norm1.bias (type: <class 'torch.Tensor'>, shape: torch.Size([1280]))
- image_proj.layers.3.0.norm1.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280]))
- image_proj.layers.3.0.norm2.bias (type: <class 'torch.Tensor'>, shape: torch.Size([1280]))
- image_proj.layers.3.0.norm2.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280]))
- image_proj.layers.3.0.to_kv.weight (type: <class 'torch.Tensor'>, shape: torch.Size([2560, 1280]))
- image_proj.layers.3.0.to_out.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 1280]))
- image_proj.layers.3.0.to_q.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 1280]))
- image_proj.layers.3.1.0.bias (type: <class 'torch.Tensor'>, shape: torch.Size([1280]))
- image_proj.layers.3.1.0.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280]))
- image_proj.layers.3.1.1.weight (type: <class 'torch.Tensor'>, shape: torch.Size([5120, 1280]))
- image_proj.layers.3.1.3.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 5120]))
- image_proj.norm_out.bias (type: <class 'torch.Tensor'>, shape: torch.Size([2048]))
- image_proj.norm_out.weight (type: <class 'torch.Tensor'>, shape: torch.Size([2048]))
- image_proj.proj_in.bias (type: <class 'torch.Tensor'>, shape: torch.Size([1280]))
- image_proj.proj_in.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 1280]))
- image_proj.proj_out.bias (type: <class 'torch.Tensor'>, shape: torch.Size([2048]))
- image_proj.proj_out.weight (type: <class 'torch.Tensor'>, shape: torch.Size([2048, 1280]))
- ip_adapter.1.to_k_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([640, 2048]))
- ip_adapter.1.to_v_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([640, 2048]))
- ip_adapter.101.to_k_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.101.to_v_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.103.to_k_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.103.to_v_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.105.to_k_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.105.to_v_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.107.to_k_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.107.to_v_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.109.to_k_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([640, 2048]))
- ip_adapter.109.to_v_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([640, 2048]))
- ip_adapter.11.to_k_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.11.to_v_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.111.to_k_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([640, 2048]))
- ip_adapter.111.to_v_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([640, 2048]))
- ip_adapter.113.to_k_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([640, 2048]))
- ip_adapter.113.to_v_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([640, 2048]))
- ip_adapter.115.to_k_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([640, 2048]))
- ip_adapter.115.to_v_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([640, 2048]))
- ip_adapter.117.to_k_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([640, 2048]))
- ip_adapter.117.to_v_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([640, 2048]))
- ip_adapter.119.to_k_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([640, 2048]))
- ip_adapter.119.to_v_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([640, 2048]))
- ip_adapter.121.to_k_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.121.to_v_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.123.to_k_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.123.to_v_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.125.to_k_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.125.to_v_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.127.to_k_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.127.to_v_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.129.to_k_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.129.to_v_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.13.to_k_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.13.to_v_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.131.to_k_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.131.to_v_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.133.to_k_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.133.to_v_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.135.to_k_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.135.to_v_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.137.to_k_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.137.to_v_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.139.to_k_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.139.to_v_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.15.to_k_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.15.to_v_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.17.to_k_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.17.to_v_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.19.to_k_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.19.to_v_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.21.to_k_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.21.to_v_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.23.to_k_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.23.to_v_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.25.to_k_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.25.to_v_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.27.to_k_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.27.to_v_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.29.to_k_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.29.to_v_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.3.to_k_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([640, 2048]))
- ip_adapter.3.to_v_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([640, 2048]))
- ip_adapter.31.to_k_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.31.to_v_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.33.to_k_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.33.to_v_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.35.to_k_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.35.to_v_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.37.to_k_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.37.to_v_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.39.to_k_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.39.to_v_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.41.to_k_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.41.to_v_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.43.to_k_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.43.to_v_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.45.to_k_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.45.to_v_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.47.to_k_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.47.to_v_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.49.to_k_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.49.to_v_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.5.to_k_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([640, 2048]))
- ip_adapter.5.to_v_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([640, 2048]))
- ip_adapter.51.to_k_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.51.to_v_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.53.to_k_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.53.to_v_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.55.to_k_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.55.to_v_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.57.to_k_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.57.to_v_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.59.to_k_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.59.to_v_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.61.to_k_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.61.to_v_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.63.to_k_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.63.to_v_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.65.to_k_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.65.to_v_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.67.to_k_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.67.to_v_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.69.to_k_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.69.to_v_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.7.to_k_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([640, 2048]))
- ip_adapter.7.to_v_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([640, 2048]))
- ip_adapter.71.to_k_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.71.to_v_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.73.to_k_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.73.to_v_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.75.to_k_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.75.to_v_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.77.to_k_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.77.to_v_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.79.to_k_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.79.to_v_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.81.to_k_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.81.to_v_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.83.to_k_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.83.to_v_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.85.to_k_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.85.to_v_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.87.to_k_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.87.to_v_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.89.to_k_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.89.to_v_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.9.to_k_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.9.to_v_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.91.to_k_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.91.to_v_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.93.to_k_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.93.to_v_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.95.to_k_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.95.to_v_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.97.to_k_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.97.to_v_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.99.to_k_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
- ip_adapter.99.to_v_ip.weight (type: <class 'torch.Tensor'>, shape: torch.Size([1280, 2048]))
